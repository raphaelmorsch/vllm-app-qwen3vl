# Qwen3-VL ‚Äì Jupyter Notebook Load & Performance Test

Este notebook tem como objetivo **simular uma aplica√ß√£o real** consumindo um modelo **Qwen3-VL** deployado em um **Model Server do OpenShift AI**, realizando **infer√™ncias multimodais (imagem + texto)** sob diferentes n√≠veis de concorr√™ncia, coletando m√©tricas de **lat√™ncia, throughput e tokens/s**.
O notebook valida a viabilidade do uso do Qwen3-VL em OpenShift AI para aplica√ß√µes multimodais reais, com m√©tricas confi√°veis e comportamento previs√≠vel sob carga.

## Objetivos do Notebook

- Simular consumo real de um modelo multimodal
- Executar infer√™ncias concorrentes
- Medir lat√™ncia e throughput
- Avaliar satura√ß√£o do Model Server / GPU
- Gerar m√©tricas compar√°veis com Prometheus/Grafana

## Modelo Avaliado

- Modelo: Qwen3-VL
- Serving: vLLM
- Endpoint: OpenAI-compatible (`/v1/chat/completions`)
- Plataforma: OpenShift AI

## Entrada Multimodal

As requisi√ß√µes incluem:
- Prompt textual: *‚ÄúDescreva a imagem em portugu√™s.‚Äù*
- Imagem via URL (lista em `images.txt`)

## Arquitetura do Teste

- Fun√ß√£o `run_inference`: executa uma infer√™ncia multimodal individual
- Fun√ß√£o `load_test`: executa infer√™ncias concorrentes com `ThreadPoolExecutor`

## M√©tricas Coletadas

- Lat√™ncia m√©dia
- Lat√™ncia P95
- Lat√™ncia m√°xima
- Throughput (req/s)
- Throughput de tokens (tokens/s)
- Tokens de entrada e sa√≠da
- Erros

## Throughput de Tokens

Calculado como:

```
total_completion_tokens / tempo_total_do_teste
```

## Comportamento sob Carga

- Aumento progressivo de lat√™ncia
- Plat√¥ de tokens/s
- Satura√ß√£o previs√≠vel da GPU
- Crescimento da fila interna do vLLM

## Observabilidade

M√©tricas client-side correlacionadas com:
- Prometheus (`/metrics` do vLLM)
- Grafana (GPU, VRAM, tokens/s, erros)

#### A seguir tutorial de como habilitar Prometheus e Grafana como plataforma de Observabilidade para o Modelo em Servidor vLLM


# **Tutorial completo de Observabilidade**

## **Observabilidade de vLLM no OpenShift AI**

**Prometheus (User Workload) \+ Grafana \+ Dashboard customizado**

---

## **Objetivo**

* Coletar m√©tricas do **vLLM** (`/metrics`)  
* Usar o **Prometheus User Workload**  
* Consultar m√©tricas corretamente via **Thanos Querier**  
* Visualizar tudo em um **Grafana customizado**  
* Ter dashboards claros para **throughput, lat√™ncia e satura√ß√£o de GPU**

---

## **Arquitetura final (mental model)**

```
vLLM (/metrics)
   ‚Üì
ServiceMonitor
   ‚Üì
Prometheus User Workload
   ‚Üì
Thanos Querier (openshift-monitoring)
   ‚Üì
Grafana (Grafana Operator)
```

---

## **1\. Habilitar o User Workload Monitoring**

O OpenShift **n√£o coleta m√©tricas de workloads por padr√£o**.

Crie (ou edite):

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    enableUserWorkload: true
```

Verifique:

```shell
oc get ns openshift-user-workload-monitoring
```

E se o Prometheus est√° rodando:

```shell
oc get pods -n openshift-user-workload-monitoring
```

---

## **2\. Expor m√©tricas do vLLM corretamente**

O vLLM j√° exp√µe m√©tricas em:

```
GET /metrics
```

Exemplo de Service:

```
apiVersion: v1
kind: Service
metadata:
  name: vllm-metrics
  labels:
    app: vllm
spec:
  ports:
    - name: metrics
      port: 8080
      targetPort: 8080
  selector:
    app: vllm
```

---

## **3\. Validar o ServiceMonitor** 

```
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: vllm
  namespace: <seu-namespace>
spec:
  selector:
    matchLabels:
      app: vllm
  endpoints:
    - port: metrics
      path: /metrics
      interval: 15s
```

Confirma√ß√£o r√°pida:

```shell
oc -n openshift-user-workload-monitoring get servicemonitors
```

---

## **4\. Validar m√©tricas no OpenShift (sanity check)**

Antes de Grafana, **sempre valide aqui**:

* OpenShift Console  
* **Observe ‚Üí Metrics**

Teste:

```
{__name__=~"vllm.*"}
```

Se aparecer ‚Üí coleta OK.

---

## **5\. Instalar o Grafana Operator**

Via OperatorHub:

* **Grafana Operator**  
* **Instale em All Namespaces**  
* Criar as Ins√¢ncias do Grafana (pr√≥ximos passos) no Namespace dedicado (ex: `grafana`)

---

## **6\. Criar a inst√¢ncia do Grafana**

```
apiVersion: grafana.integreatly.org/v1beta1
kind: Grafana
metadata:
  name: grafana
  namespace: grafana
  labels:
    dashboards: vllm
spec:
  ingress:
    enabled: true
```

Criar a rota (o Ingress enabled n√£o √© v√°lido nesta vers√£o):

```shell
oc expose svc <seu-grafana-service> -n grafana
```

---

## **7\. O erro cl√°ssico (e a corre√ß√£o certa)**

### **N√ÉO use (no GrafanaDatasource):**

```
prometheus-user-workload.openshift-user-workload-monitoring.svc:9091
```

Esse endpoint **s√≥ exp√µe `/metrics`**, n√£o PromQL.

---

## **Endpoint CORRETO para GrafanaDatasource**

üëâ **Thanos Querier**

```
https://thanos-querier.openshift-monitoring.svc:9091
```

Esse √© o endpoint **oficial e suportado**.

---

## **8\. Criar o token correto (sem expirar)**

Crie um **ServiceAccount dedicado**:

```shell
oc create sa grafana-prometheus -n grafana
```

Associe a role:

```shell
oc adm policy add-cluster-role-to-user \
  cluster-monitoring-view \
  -z grafana-prometheus \
  -n grafana
```

Pegue o token:

```shell
oc create token grafana-prometheus -n grafana
```

---

## **9. Criar o GrafanaDatasource (funcional)**

```
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDatasource
metadata:
  name: prometheus-ds
  namespace: grafana
spec:
  datasource:
    name: Prometheus
    type: prometheus
    access: proxy
    url: https://thanos-querier.openshift-monitoring.svc:9091
    isDefault: true
    jsonData:
      tlsSkipVerify: true
      httpMethod: POST
    secureJsonData:
      httpHeaderValue1: "Bearer <TOKEN_DO_SA>"
  instanceSelector:
    matchLabels:
      dashboards: vllm
```

---

## **10\. Testes no Grafana ‚Üí Explore**

Teste nesta ordem:

```
up
```

```
{__name__=~"vllm.*"}
```

```
sum(rate(vllm:prompt_tokens_total[1m]))
```

Se isso funciona ‚Üí tudo OK.

---

## **11\. Queries vLLM usadas no Dashboard**

### **Throughput**

```
sum(rate(vllm:prompt_tokens_total[1m]))
```

### **Requests em execu√ß√£o**

```
sum(vllm:num_requests_running)
```

### **Requests em fila**

```
sum(vllm:num_requests_waiting)
```

### **Lat√™ncia p95**

```
histogram_quantile(
  0.95,
  sum by (le)(rate(vllm:request_latency_seconds_bucket[5m]))
)
```

---

## **12\. Organiza√ß√£o visual do Dashboard**

* Grid de **24 colunas**  
* Panels lado a lado (`w=6`, `w=8`, `w=12`)  
* Uso de **Rows**:  
  * Overview  
  * Latency  
  * Queue & Saturation  
  * GPU

Layout t√≠pico:

```
[ Tokens/s | Running | Waiting | Errors ]
[        Latency p50 / p95 / p99          ]
[     GPU Util     |    GPU Memory        ]
```



